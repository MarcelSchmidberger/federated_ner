{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Federated Learning Training Plan: Create Plan\n",
    "\n",
    "Let's try to make protobuf-serializable Training Plan and Model that work after deserializing :)\n",
    "\n",
    "Current list of problems:\n",
    " * `tensor.shape` is not traceable inside the Plan (issue [#3554](https://github.com/OpenMined/PySyft/issues/3554)).\n",
    " * Autograd/Plan tracing doesn't work with native torch's loss functions and optimizers.\n",
    " * others?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Falling back to insecure randomness since the required custom op could not be found for the installed version of TensorFlow. Fix this by compiling custom ops. Missing file was '/home/marcel/Documents/Uni/susml/PySyft/venv/lib/python3.7/site-packages/tf_encrypted/operations/secure_random/secure_random_module_tf_1.15.0.so'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/marcel/Documents/Uni/susml/PySyft/venv/lib/python3.7/site-packages/tf_encrypted/session.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Setting up Sandbox...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9f2d4ee830>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import syft as sy\n",
    "import torch as th\n",
    "from torch import jit\n",
    "from torch import nn\n",
    "from syft.serde import protobuf\n",
    "import os\n",
    "from syft.execution.state import State\n",
    "from syft.execution.placeholder import PlaceHolder\n",
    "\n",
    "\n",
    "\n",
    "sy.make_hook(globals())\n",
    "# force protobuf serialization for tensors\n",
    "hook.local_worker.framework = None\n",
    "th.random.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This utility function will serialize any object to protobuf binary and save to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def serialize_to_bin_pb(worker, obj, filename):\n",
    "    pb = protobuf.serde._bufferize(worker, obj)\n",
    "    bin = pb.SerializeToString()\n",
    "    print(\"Writing %s to %s/%s\" % (obj.__class__.__name__, os.getcwd(), filename))\n",
    "    with open(filename, \"wb\") as f:\n",
    "        f.write(bin)\n",
    "\n",
    "\n",
    "def set_model_params(module, params_list, start_param_idx=0):\n",
    "    \"\"\" Set params list into model recursively\n",
    "    \"\"\"\n",
    "    param_idx = start_param_idx\n",
    "\n",
    "    for name, param in module._parameters.items():\n",
    "        module._parameters[name] = params_list[param_idx]\n",
    "        param_idx += 1\n",
    "\n",
    "    for name, child in module._modules.items():\n",
    "        if child is not None:\n",
    "            param_idx += set_model_params(child, params_list, param_idx)\n",
    "\n",
    "    return param_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 1: Define the model\n",
    "\n",
    "This model will train on MNIST data, it's very simple yet can demonstrate learning process.\n",
    "There're 2 linear layers: \n",
    "\n",
    "* Linear 784x392\n",
    "* ReLU\n",
    "* Linear 392x10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 392)\n",
    "        self.fc2 = nn.Linear(392, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 2: Define Training Plan\n",
    "### Loss function \n",
    "Batch size needs to be passed because otherwise `target.shape[0]` is not traced inside Plan yet (Issue [#3554](https://github.com/OpenMined/PySyft/issues/3554)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def softmax_cross_entropy_with_logits(logits, targets, batch_size):\n",
    "    \"\"\" Calculates softmax entropy\n",
    "        Args:\n",
    "            * logits: (NxC) outputs of dense layer\n",
    "            * targets: (NxC) one-hot encoded labels\n",
    "            * batch_size: value of N, temporarily required because Plan cannot trace .shape\n",
    "    \"\"\"\n",
    "    # numstable logsoftmax\n",
    "    norm_logits = logits - logits.max()\n",
    "    log_probs = norm_logits - norm_logits.exp().sum(dim=1, keepdim=True).log()\n",
    "    # NLL, reduction = mean\n",
    "    return -(targets * log_probs).sum() / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Optimization function\n",
    " \n",
    "Just updates weights with grad*lr.\n",
    "\n",
    "Note: can't do inplace update because of Autograd/Plan tracing specifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def naive_sgd(param, **kwargs):\n",
    "    return param - kwargs['lr'] * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training Plan procedure\n",
    "\n",
    "We define a routine that will take one batch of training data, and model parameters,\n",
    "and will update model parameters to optimize them for given loss function using SGD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "@sy.func2plan()\n",
    "def training_plan(X, y, batch_size, lr, model_params):\n",
    "    # inject params into model\n",
    "    set_model_params(model, model_params)\n",
    "\n",
    "    # forward pass\n",
    "    logits = model.forward(X)\n",
    "    \n",
    "    # loss\n",
    "    loss = softmax_cross_entropy_with_logits(logits, y, batch_size)\n",
    "\n",
    "    # backprop\n",
    "    loss.backward()\n",
    "\n",
    "    # step\n",
    "    updated_params = [\n",
    "        naive_sgd(param, lr=lr)\n",
    "        for param in model_params\n",
    "    ]\n",
    "    \n",
    "    # accuracy\n",
    "    pred = th.argmax(logits, dim=1)\n",
    "    target = th.argmax(y, dim=1)\n",
    "    acc = pred.eq(target).sum().float() / batch_size\n",
    "\n",
    "    return (\n",
    "        loss,\n",
    "        acc,\n",
    "        *updated_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's build this procedure into the Plan that we can serialize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy input parameters to make the trace\n",
    "model_params = list(model.parameters())\n",
    "X = th.randn(3, 28 * 28)\n",
    "y = nn.functional.one_hot(th.tensor([1, 2, 3]), 10)\n",
    "lr = th.tensor([0.01])\n",
    "batch_size = th.tensor([3.0])\n",
    "\n",
    "_ = training_plan.build(X, y, batch_size, lr, model_params, trace_autograd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0184, -0.0158, -0.0069,  ...,  0.0068, -0.0041,  0.0025],\n",
       "         [-0.0274, -0.0224, -0.0309,  ..., -0.0029,  0.0013, -0.0167],\n",
       "         [ 0.0282, -0.0095, -0.0340,  ..., -0.0141,  0.0056, -0.0335],\n",
       "         ...,\n",
       "         [ 0.0020,  0.0007, -0.0162,  ..., -0.0104,  0.0319, -0.0277],\n",
       "         [-0.0087, -0.0188,  0.0324,  ...,  0.0356, -0.0055, -0.0190],\n",
       "         [ 0.0086, -0.0189, -0.0041,  ..., -0.0191,  0.0115,  0.0309]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-3.0040e-02, -1.8273e-02,  3.9988e-04, -1.0971e-03,  1.9602e-02,\n",
       "          1.0877e-02,  1.9399e-02, -3.2868e-02,  2.7105e-02, -8.4035e-03,\n",
       "         -1.9864e-02, -1.5975e-02,  9.3535e-03, -1.5757e-04, -1.8987e-02,\n",
       "         -2.1302e-02,  2.7492e-02,  1.7803e-02, -3.4343e-02,  4.4279e-03,\n",
       "         -1.8821e-02,  4.3425e-03,  1.2906e-02,  3.3424e-02,  1.5087e-03,\n",
       "          2.3612e-02, -1.9434e-02, -1.2945e-02, -1.2356e-02,  2.2264e-02,\n",
       "          1.5426e-02,  3.4883e-04,  7.9607e-03, -5.0961e-03, -3.4520e-02,\n",
       "         -2.2605e-02, -6.5501e-03, -1.5668e-02, -2.5868e-02,  2.3900e-02,\n",
       "          1.5677e-02,  1.6647e-02, -6.7345e-03, -3.0145e-02, -3.3537e-02,\n",
       "         -2.1739e-02, -1.5173e-02, -3.3685e-02,  1.8947e-02, -3.5151e-02,\n",
       "         -1.6374e-02, -1.2123e-02,  3.0922e-02, -1.2289e-03, -2.4732e-02,\n",
       "         -2.6034e-02,  1.1977e-02,  1.0751e-02, -1.3606e-02, -2.6747e-03,\n",
       "          2.7330e-02, -3.3084e-02, -1.0496e-02, -7.1800e-03,  1.2595e-02,\n",
       "          2.7305e-02,  2.0547e-03,  5.0979e-03, -1.3047e-03, -1.6206e-02,\n",
       "         -2.4403e-02,  3.5515e-02, -1.0267e-02,  1.9448e-02, -2.4606e-02,\n",
       "         -1.4884e-02,  5.4200e-03, -1.2304e-02,  1.2337e-02,  1.7614e-02,\n",
       "          2.2079e-03, -2.3899e-02, -4.2588e-03, -2.6651e-02,  2.4355e-02,\n",
       "          1.4917e-02,  2.5024e-02, -1.1319e-02, -2.2146e-02,  1.6678e-03,\n",
       "          9.8657e-03, -1.7800e-02,  2.1188e-02,  3.3209e-02,  3.5375e-02,\n",
       "         -3.4679e-02, -2.9407e-02,  3.4130e-02, -2.1087e-02, -3.2229e-02,\n",
       "         -1.1259e-02, -1.0111e-02,  8.0826e-03, -1.4899e-02,  1.5679e-02,\n",
       "         -3.1227e-02,  3.1438e-02,  2.6941e-02,  1.0221e-02, -2.2864e-02,\n",
       "         -1.3266e-02, -4.9048e-04, -1.4487e-02,  3.2622e-03, -9.0260e-03,\n",
       "         -7.0043e-05,  3.7867e-03, -4.6307e-03, -4.6945e-03, -2.7204e-02,\n",
       "          3.5494e-02,  7.4446e-03,  1.8904e-02,  1.4614e-02,  1.3562e-02,\n",
       "         -2.0807e-02,  2.8620e-02,  2.2539e-02,  1.8165e-03,  1.5633e-02,\n",
       "          2.6695e-02,  1.3379e-02, -1.0509e-02,  1.7880e-02, -7.2702e-03,\n",
       "         -2.3918e-02, -3.0472e-02, -3.2206e-03, -1.5480e-02,  2.4006e-02,\n",
       "         -3.1611e-02, -6.9570e-03,  6.0524e-03,  2.5283e-02, -1.6472e-02,\n",
       "          7.2691e-03,  1.7555e-03, -2.2099e-02,  3.4191e-02,  1.6691e-02,\n",
       "         -1.1483e-02,  2.4547e-02,  1.5198e-02, -3.6000e-03, -3.0661e-03,\n",
       "          2.8492e-02, -4.1359e-03,  6.0227e-03,  3.6168e-03, -3.0587e-02,\n",
       "         -1.4795e-03,  3.0806e-02, -4.3655e-03, -2.6659e-02, -1.5049e-02,\n",
       "          2.3341e-02,  2.4726e-02,  1.9433e-02, -1.7265e-02, -7.4366e-03,\n",
       "          2.6514e-02,  1.4346e-03,  1.8074e-02,  1.7643e-02, -2.2890e-02,\n",
       "         -3.2457e-02,  2.0555e-03, -1.3619e-02, -3.2902e-02, -2.5274e-02,\n",
       "          9.1160e-04, -2.2330e-02, -2.9245e-02,  2.0484e-02,  1.7819e-02,\n",
       "          3.1590e-02, -4.6808e-03,  1.8970e-02, -2.5521e-02,  2.8830e-04,\n",
       "          1.1301e-02,  2.0343e-02,  3.2940e-04, -3.2685e-02, -1.7081e-02,\n",
       "         -3.1827e-02, -2.7928e-02, -6.5702e-03, -3.4525e-02,  2.1441e-02,\n",
       "         -1.8308e-02, -2.2989e-02,  5.4878e-03,  4.6234e-03,  6.8083e-03,\n",
       "         -2.5027e-02, -4.2669e-03, -3.1709e-02,  2.9583e-02, -1.6767e-02,\n",
       "         -2.2904e-03, -9.0371e-03, -1.3753e-02,  3.1542e-02, -3.0978e-02,\n",
       "          8.6785e-03, -5.5724e-03,  3.5554e-02,  7.5276e-03, -8.8062e-03,\n",
       "         -1.0069e-02,  1.3888e-03, -1.3117e-02, -3.3105e-02,  1.0230e-02,\n",
       "         -2.2951e-02, -3.0707e-02, -3.3507e-02, -8.0179e-03, -1.2352e-02,\n",
       "         -1.4252e-02,  2.2869e-02, -1.4319e-02, -2.2273e-03,  2.3596e-02,\n",
       "          1.2983e-03,  8.5196e-03,  1.6600e-02, -8.8538e-03,  4.0789e-03,\n",
       "          1.1974e-03,  1.3162e-02, -1.1025e-02, -4.9378e-03, -2.9367e-02,\n",
       "          4.5363e-03, -2.2903e-02, -9.7926e-03,  3.2122e-03,  2.3608e-02,\n",
       "          1.2088e-02, -5.3087e-03,  1.9383e-02,  2.7340e-02, -2.7631e-02,\n",
       "         -3.5562e-02, -1.8123e-02, -6.1224e-03, -9.9631e-03, -1.4460e-02,\n",
       "          3.0608e-02, -2.5640e-02,  1.7861e-02, -5.9241e-03,  2.8699e-02,\n",
       "          1.2475e-02,  1.4193e-02,  8.5176e-03, -3.3308e-02,  1.5018e-02,\n",
       "          2.4678e-02,  1.5694e-02, -2.3239e-02,  3.0668e-02,  8.9880e-03,\n",
       "          2.9107e-02, -2.2690e-02, -1.1247e-02, -3.1630e-02, -3.3464e-02,\n",
       "         -3.0082e-02,  3.4582e-02, -2.6430e-02,  4.0968e-03, -2.9039e-02,\n",
       "         -1.5020e-02, -7.4666e-03,  2.1444e-02,  2.7755e-02,  3.0437e-02,\n",
       "          4.3577e-03, -3.1466e-02, -1.3301e-02,  3.0529e-02, -3.3081e-02,\n",
       "         -1.1787e-02,  1.4106e-02,  1.3874e-02,  2.3685e-02, -2.7244e-02,\n",
       "          1.5796e-02,  1.0006e-02,  2.0854e-02,  2.4813e-02, -1.4745e-02,\n",
       "          7.9106e-03,  9.1959e-03, -3.5325e-02, -7.6813e-03, -3.0365e-02,\n",
       "         -1.1553e-02, -3.2326e-02, -3.3299e-02,  2.6359e-02,  2.0784e-02,\n",
       "          2.2539e-02, -3.2527e-02,  2.5276e-02, -1.5467e-02,  2.5410e-02,\n",
       "         -3.0841e-02, -2.5064e-02, -3.4410e-02, -1.4112e-02,  3.3344e-02,\n",
       "          1.2871e-02,  2.5559e-02,  1.3632e-02,  1.4542e-02,  3.1496e-02,\n",
       "         -6.2968e-03,  1.2291e-02, -1.3317e-02,  2.6260e-02,  2.5257e-02,\n",
       "         -3.2129e-02,  1.3771e-02, -1.6720e-02, -2.5060e-03, -2.6773e-02,\n",
       "         -6.6516e-03,  2.0211e-04,  3.4143e-02, -2.9862e-03,  3.0387e-02,\n",
       "         -1.2600e-02, -1.5178e-02,  8.5101e-03, -5.8552e-03, -2.5099e-02,\n",
       "          1.2625e-02,  7.3028e-04, -2.6942e-02, -1.6387e-02, -3.1648e-02,\n",
       "         -3.0434e-02,  3.5464e-02,  1.3546e-02, -2.1135e-02, -3.0104e-02,\n",
       "          1.8571e-02, -2.0882e-02, -3.4572e-02, -9.0793e-03, -2.5796e-02,\n",
       "         -6.6095e-04, -2.0066e-02, -2.6461e-02, -2.6755e-02, -2.1844e-02,\n",
       "          1.2954e-02, -1.2378e-02, -4.8938e-03,  1.1761e-02,  2.4268e-02,\n",
       "         -2.0555e-02,  2.4298e-02,  1.6567e-03, -3.0842e-02,  1.4626e-02,\n",
       "          3.2977e-02,  3.4739e-02, -1.6071e-02,  1.0162e-02, -7.5725e-04,\n",
       "          2.0254e-02,  6.4786e-03,  2.7407e-02, -3.1111e-03, -1.3150e-02,\n",
       "         -1.1709e-02,  3.3264e-02], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0289,  0.0051, -0.0391,  ...,  0.0016, -0.0387, -0.0408],\n",
       "         [ 0.0293,  0.0310,  0.0317,  ...,  0.0321,  0.0460, -0.0033],\n",
       "         [ 0.0112, -0.0330, -0.0022,  ...,  0.0503, -0.0400, -0.0211],\n",
       "         ...,\n",
       "         [ 0.0458,  0.0027, -0.0407,  ..., -0.0476, -0.0275,  0.0234],\n",
       "         [-0.0437, -0.0268,  0.0430,  ...,  0.0350,  0.0146,  0.0083],\n",
       "         [ 0.0295, -0.0204, -0.0134,  ..., -0.0219,  0.0441,  0.0002]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0315,  0.0434,  0.0444,  0.0481, -0.0192, -0.0382,  0.0316, -0.0022,\n",
       "          0.0101,  0.0447], requires_grad=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's look inside the Syft Plan and print out the list of operations recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def training_plan(arg_1, arg_2, arg_3, arg_4, arg_5, arg_6, arg_7, arg_8):\n",
      "    2 = arg_1.dim()\n",
      "    var_0 = arg_5.t()\n",
      "    var_1 = arg_1.matmul(var_0)\n",
      "    var_2 = arg_6.add(var_1)\n",
      "    var_3 = var_2.relu()\n",
      "    2 = var_3.dim()\n",
      "    var_4 = arg_7.t()\n",
      "    var_5 = var_3.matmul(var_4)\n",
      "    var_6 = arg_8.add(var_5)\n",
      "    var_7 = var_6.max()\n",
      "    var_8 = var_6.sub(var_7)\n",
      "    var_9 = var_8.exp()\n",
      "    var_10 = var_9.sum(dim=1, keepdim=True)\n",
      "    var_11 = var_10.log()\n",
      "    var_12 = var_8.sub(var_11)\n",
      "    var_13 = arg_2.mul(var_12)\n",
      "    var_14 = var_13.sum()\n",
      "    var_15 = var_14.neg()\n",
      "    out_1 = var_15.div(arg_3)\n",
      "    var_16 = out_1.mul(0)\n",
      "    var_17 = var_16.add(1)\n",
      "    var_18 = var_17.div(arg_3)\n",
      "    var_19 = var_18.mul(-1)\n",
      "    var_20 = var_19.reshape(-1, 1)\n",
      "    var_21 = var_13.mul(0)\n",
      "    var_22 = var_21.add(1)\n",
      "    var_23 = var_22.mul(var_20)\n",
      "    var_24 = var_23.mul(var_12)\n",
      "    var_25 = var_23.mul(arg_2)\n",
      "    var_26 = var_24.copy()\n",
      "    var_27 = var_25.add(0)\n",
      "    var_28 = var_25.mul(-1)\n",
      "    var_29 = var_28.sum(dim=[1], keepdim=True)\n",
      "    var_30 = var_27.add(0)\n",
      "    var_31 = var_27.mul(-1)\n",
      "    var_32 = var_31.sum(dim=[1, 0])\n",
      "    var_33 = var_30.add(0)\n",
      "    var_34 = var_30.add(0)\n",
      "    var_35 = var_33.sum(dim=[0])\n",
      "    var_36 = var_35.copy()\n",
      "    var_37 = var_4.t()\n",
      "    var_38 = var_34.matmul(var_37)\n",
      "    var_39 = var_3.t()\n",
      "    var_40 = var_39.matmul(var_34)\n",
      "    var_41 = var_2.mul(0)\n",
      "    var_42 = var_2.__gt__(var_41)\n",
      "    var_43 = var_42.mul(var_38)\n",
      "    var_44 = var_43.add(0)\n",
      "    var_45 = var_43.add(0)\n",
      "    var_46 = var_44.sum(dim=[0])\n",
      "    var_47 = var_46.copy()\n",
      "    var_48 = var_0.t()\n",
      "    var_49 = var_45.matmul(var_48)\n",
      "    var_50 = arg_1.t()\n",
      "    var_51 = var_50.matmul(var_45)\n",
      "    var_52 = var_49.copy()\n",
      "    var_53 = var_51.t()\n",
      "    var_54 = var_53.copy()\n",
      "    var_55 = var_40.t()\n",
      "    var_56 = var_55.copy()\n",
      "    var_57 = var_32.copy()\n",
      "    var_58 = var_10.__rtruediv__(1)\n",
      "    var_59 = var_29.mul(var_58)\n",
      "    var_60 = var_59.reshape(-1, 1)\n",
      "    var_61 = var_9.mul(0)\n",
      "    var_62 = var_61.add(1)\n",
      "    var_63 = var_62.mul(var_60)\n",
      "    var_64 = var_8.exp()\n",
      "    var_65 = var_63.mul(var_64)\n",
      "    var_66 = var_65.add(0)\n",
      "    var_67 = var_65.mul(-1)\n",
      "    var_68 = var_67.sum(dim=[1, 0])\n",
      "    var_69 = var_66.add(0)\n",
      "    var_70 = var_66.add(0)\n",
      "    var_71 = var_69.sum(dim=[0])\n",
      "    var_72 = var_36.add_(var_71)\n",
      "    var_73 = var_4.t()\n",
      "    var_74 = var_70.matmul(var_73)\n",
      "    var_75 = var_3.t()\n",
      "    var_76 = var_75.matmul(var_70)\n",
      "    var_77 = var_2.mul(0)\n",
      "    var_78 = var_2.__gt__(var_77)\n",
      "    var_79 = var_78.mul(var_74)\n",
      "    var_80 = var_79.add(0)\n",
      "    var_81 = var_79.add(0)\n",
      "    var_82 = var_80.sum(dim=[0])\n",
      "    var_83 = var_47.add_(var_82)\n",
      "    var_84 = var_0.t()\n",
      "    var_85 = var_81.matmul(var_84)\n",
      "    var_86 = arg_1.t()\n",
      "    var_87 = var_86.matmul(var_81)\n",
      "    var_88 = var_52.add_(var_85)\n",
      "    var_89 = var_87.t()\n",
      "    var_90 = var_54.add_(var_89)\n",
      "    var_91 = var_76.t()\n",
      "    var_92 = var_56.add_(var_91)\n",
      "    var_93 = var_57.add_(var_68)\n",
      "    var_94 = arg_4.mul(var_54)\n",
      "    out_3 = arg_5.sub(var_94)\n",
      "    var_95 = arg_4.mul(var_47)\n",
      "    out_4 = arg_6.sub(var_95)\n",
      "    var_96 = arg_4.mul(var_56)\n",
      "    out_5 = arg_7.sub(var_96)\n",
      "    var_97 = arg_4.mul(var_36)\n",
      "    out_6 = arg_8.sub(var_97)\n",
      "    var_98 = torch.argmax(var_6, dim=1)\n",
      "    var_99 = torch.argmax(arg_2, dim=1)\n",
      "    var_100 = var_98.eq(var_99)\n",
      "    var_101 = var_100.sum()\n",
      "    var_102 = var_101.float()\n",
      "    out_2 = var_102.div(arg_3)\n",
      "    return out_1, out_2, out_3, out_4, out_5, out_6\n"
     ]
    }
   ],
   "source": [
    "print(training_plan.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Plan should be automatically translated to torchscript, too.\n",
    "Let's examine torchscript code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def <Plan training_plan id:76566451657 owner:me built>\n",
      "(argument_0: Tensor,\n",
      "    argument_1: Tensor,\n",
      "    argument_2: Tensor,\n",
      "    argument_3: Tensor,\n",
      "    argument_4: List[Tensor]) -> Tuple[Tensor, Tensor, Tensor, Tensor, Tensor, Tensor]:\n",
      "  _0, _1, _2, _3, = argument_4\n",
      "  _4 = torch.add(_1, torch.matmul(argument_0, torch.t(_0)), alpha=1)\n",
      "  _5 = torch.relu(_4)\n",
      "  _6 = torch.t(_2)\n",
      "  _7 = torch.add(_3, torch.matmul(_5, _6), alpha=1)\n",
      "  _8 = torch.sub(_7, torch.max(_7), alpha=1)\n",
      "  _9 = torch.exp(_8)\n",
      "  _10 = torch.sum(_9, [1], True, dtype=None)\n",
      "  _11 = torch.sub(_8, torch.log(_10), alpha=1)\n",
      "  _12 = torch.mul(argument_1, _11)\n",
      "  _13 = torch.div(torch.neg(torch.sum(_12, dtype=None)), argument_2)\n",
      "  _14 = torch.add(torch.mul(_13, CONSTANTS.c0), CONSTANTS.c1, alpha=1)\n",
      "  _15 = torch.mul(torch.div(_14, argument_2), CONSTANTS.c2)\n",
      "  _16 = torch.reshape(_15, [-1, 1])\n",
      "  _17 = torch.add(torch.mul(_12, CONSTANTS.c0), CONSTANTS.c1, alpha=1)\n",
      "  _18 = torch.mul(torch.mul(_17, _16), argument_1)\n",
      "  _19 = torch.add(_18, CONSTANTS.c0, alpha=1)\n",
      "  _20 = torch.sum(torch.mul(_18, CONSTANTS.c2), [1], True, dtype=None)\n",
      "  _21 = torch.add(_19, CONSTANTS.c0, alpha=1)\n",
      "  _22 = torch.add(_21, CONSTANTS.c0, alpha=1)\n",
      "  _23 = torch.add(_21, CONSTANTS.c0, alpha=1)\n",
      "  _24 = torch.sum(_22, [0], False, dtype=None)\n",
      "  _25 = torch.matmul(_23, torch.t(_6))\n",
      "  _26 = torch.matmul(torch.t(_5), _23)\n",
      "  _27 = torch.gt(_4, torch.mul(_4, CONSTANTS.c0))\n",
      "  _28 = torch.mul(_27, _25)\n",
      "  _29 = torch.add(_28, CONSTANTS.c0, alpha=1)\n",
      "  _30 = torch.add(_28, CONSTANTS.c0, alpha=1)\n",
      "  _31 = torch.sum(_29, [0], False, dtype=None)\n",
      "  _32 = torch.matmul(torch.t(argument_0), _30)\n",
      "  _33 = torch.t(_32)\n",
      "  _34 = torch.t(_26)\n",
      "  _35 = torch.mul(torch.reciprocal(_10), CONSTANTS.c1)\n",
      "  _36 = torch.reshape(torch.mul(_20, _35), [-1, 1])\n",
      "  _37 = torch.add(torch.mul(_9, CONSTANTS.c0), CONSTANTS.c1, alpha=1)\n",
      "  _38 = torch.mul(torch.mul(_37, _36), torch.exp(_8))\n",
      "  _39 = torch.add(_38, CONSTANTS.c0, alpha=1)\n",
      "  _40 = torch.add(_39, CONSTANTS.c0, alpha=1)\n",
      "  _41 = torch.add(_39, CONSTANTS.c0, alpha=1)\n",
      "  _42 = torch.sum(_40, [0], False, dtype=None)\n",
      "  _43 = torch.add_(_24, _42, alpha=1)\n",
      "  _44 = torch.matmul(_41, torch.t(_6))\n",
      "  _45 = torch.matmul(torch.t(_5), _41)\n",
      "  _46 = torch.gt(_4, torch.mul(_4, CONSTANTS.c0))\n",
      "  _47 = torch.mul(_46, _44)\n",
      "  _48 = torch.add(_47, CONSTANTS.c0, alpha=1)\n",
      "  _49 = torch.add(_47, CONSTANTS.c0, alpha=1)\n",
      "  _50 = torch.sum(_48, [0], False, dtype=None)\n",
      "  _51 = torch.add_(_31, _50, alpha=1)\n",
      "  _52 = torch.matmul(torch.t(argument_0), _49)\n",
      "  _53 = torch.add_(_33, torch.t(_52), alpha=1)\n",
      "  _54 = torch.add_(_34, torch.t(_45), alpha=1)\n",
      "  _55 = torch.sub(_0, torch.mul(argument_3, _53), alpha=1)\n",
      "  _56 = torch.sub(_1, torch.mul(argument_3, _51), alpha=1)\n",
      "  _57 = torch.sub(_2, torch.mul(argument_3, _54), alpha=1)\n",
      "  _58 = torch.sub(_3, torch.mul(argument_3, _43), alpha=1)\n",
      "  _59 = torch.eq(torch.argmax(_7, 1, False), torch.argmax(argument_1, 1, False))\n",
      "  _60 = torch.to(torch.sum(_59, dtype=None), 6, False, False, None)\n",
      "  _61 = (_13, torch.div(_60, argument_2), _55, _56, _57, _58)\n",
      "  return _61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(training_plan.torchscript.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Step 3: Serialize!\n",
    "\n",
    "Now it's time to serialize model params and plans to protobuf and save them for further usage:\n",
    " * In \"Execute Plan\" notebook, we load and execute these plans & model, from Python.\n",
    " * In \"Host Plan\" notebook, we send these plans & model to PyGrid, so it can be executed from other worker (e.g. syft.js).\n",
    "\n",
    "**NOTE:**\n",
    " * We don't serialize full Model, only weights. How the Model is serialized is TBD.\n",
    "   State is suitable protobuf class to wrap list of Model params tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Plan to /home/marcel/Documents/Uni/susml/PySyft/examples/experimental/FL Training Plan/tp_full.pb\n",
      "Writing State to /home/marcel/Documents/Uni/susml/PySyft/examples/experimental/FL Training Plan/model_params.pb\n"
     ]
    }
   ],
   "source": [
    "serialize_to_bin_pb(hook.local_worker, training_plan, \"tp_full.pb\")\n",
    "\n",
    "# wrap weights in State to serialize\n",
    "model_params_state = State(\n",
    "    state_placeholders=[\n",
    "        PlaceHolder().instantiate(param)\n",
    "        for param in model_params\n",
    "    ]\n",
    ")\n",
    "\n",
    "serialize_to_bin_pb(hook.local_worker, model_params_state, \"model_params.pb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft",
   "language": "python",
   "name": "pysyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
